	- [Call global SNPs](#Call-global-snps)
	- [Check output](#Check-output)
# Call global SNPs
Okay so we figured out what our parameters for min depth (MINDP), max depth (MAXDP) should be in previous step\
Now we call global (for all samples) snps using those snp filter parameters \
Runtime: 13h50m \
`1-call_global_snps_all.mpi`

	#!/bin/bash
	#
	#SBATCH --job-name glblsnpcall_angsd
	#SBATCH --output %A_glblsnpcall_angsd.out
	#SBATCH --error %A_glblsnpcall_angsd.err
	#SBATCH --mail-type=ALL
	#SBATCH --mail-user=mabrober@ucsc.edu
	#SBATCH --time=15-00:00:00
	#SBATCH --partition 128x24
	#SBATCH --mem=120GB   #
	#SBATCH -n 24

	## This script is used to call global SNPs using angsd
	module load angsd

	BAMLIST=DTR_dedup_bam.tsv # Name of tsv with list of paths to bamfiles to include in global SNP calling 
	LIST_DIR=/hb/groups/bernardi_lab/may/DTR/population-analysis/sample_lists/$BAMLIST
	BASEDIR=/hb/groups/bernardi_lab/may/DTR/population-analysis/ # Path to the base directory where output files will be written to a subdirectory named "angsd/".
	REFERENCE=/hb/groups/bernardi_lab/may/DTR/DTRgenome/genome_annot/genome/kuro_filt_s500.fasta # Path to reference genome
	MINDP=100 #Minimum combined sequencing depth (MINDP), e.g. 0.33 x number of individuals # Minimum depth filter
	MAXDP=590 #MININ x estimated coverage # Maximum depth filter #maxdepth filter #Maximum combined sequencing depth across all individuals, e.g = mean depth + 4 s.d.
	MININD=13 #10% of all samples # Minimum individual filter - a read has to be present in, e.g. 10% of individuals
	MINQ=20  #Minimum quality filter #The minimum base quality score # Minimum quality filter
	MINMAF=0.05 #Minimum minor allele frequency filter
	MINMAPQ=20 ### Minimum mapping quality (alignment score) filter, default value is 20
	EXTRA_ARG='-remove_bads 1 -only_proper_pairs 1 -C 50' # Extra arguments when running ANGSD - these are default #kept getting "command not found: -remove_bads" Couldn't find almost any info on it online but supposedly its default is set to `-remove_bads 1` so take out" Runs either way. 
	THREADS=24 # Number of parallel threads to use, default value is 8.
	#-SNP_pval # (Remove sites with a pvalue larger)


	## Extract the name of the bam list (excluding path and suffix)
	BAMLISTNAME=`echo $BAMLIST | sed 's/\..*//'` #| sed -e 's#.*/\(\)#\1#'`

	## Build base name of output files
	OUTBASE=$BAMLISTNAME'_mindp'$MINDP'_maxdp'$MAXDP'_minind'$MININD'_minq'$MINQ

	## Call SNPs #GL 1 is the samtools model for genotype likelihoods
	angsd -b $LIST_DIR -ref $REFERENCE -out $BASEDIR'angsd'/$OUTBASE \
	-GL 1 -doGlf 2 -doMaf 1 -doMajorMinor 1 -doCounts 1 -doDepth 1 -maxDepth 10000 -dumpCounts 1 -doIBS 1 -makematrix 1 -doCov 1 \
	-setMinDepth $MINDP -setMaxDepth $MAXDP -minInd $MININD \
	-minQ $MINQ -minMapQ $MINMAPQ \
	-SNP_pval 1e-6 -minMaf $MINMAF \
	-P $THREADS
	$EXTRA_ARG
	>& $BASEDIR'angsd/'$OUTBASE'.log'

	## Create a SNP list to use in downstream analyses
	gunzip -c $BASEDIR'angsd/'$OUTBASE'.mafs.gz' | cut -f 1,2,3,4 | tail -n +2 > $BASEDIR'angsd/global_snp_list_'$OUTBASE'.txt'
	angsd sites index $BASEDIR'angsd/global_snp_list_'$OUTBASE'.txt'

	## Also make it in regions format for downstream analyses
	cut -f 1,2 $BASEDIR'angsd/global_snp_list_'$OUTBASE'.txt' | sed 's/\t/:/g' > $BASEDIR'angsd/global_snp_list_'$OUTBASE'.regions'

	## Lastly, extract a list of chromosomes/LGs/scaffolds for downstream analysis
	cut -f1 $BASEDIR'angsd/global_snp_list_'$OUTBASE'.txt' | sort | uniq > $BASEDIR'angsd/global_snp_list_'$OUTBASE'.chrs'

This will output these files:

	DTR_dedup_bams_mindp100_maxdp590_minind13_minq20.arg
	DTR_dedup_bams_mindp100_maxdp590_minind13_minq20.beagle.gz
	DTR_dedup_bams_mindp100_maxdp590_minind13_minq20.covMat
	DTR_dedup_bams_mindp100_maxdp590_minind13_minq20.depthGlobal
	DTR_dedup_bams_mindp100_maxdp590_minind13_minq20.depthSample
	DTR_dedup_bams_mindp100_maxdp590_minind13_minq20.ibs.gz
	DTR_dedup_bams_mindp100_maxdp590_minind13_minq20.ibsMat
	DTR_dedup_bams_mindp100_maxdp590_minind13_minq20.log
	DTR_dedup_bams_mindp100_maxdp590_minind13_minq20.mafs.gz
	DTR_dedup_bams_mindp100_maxdp590_minind13_minq20.pos.gz
	global_snp_list_DTR_dedup_bams_mindp100_maxdp590_minind13_minq20.chrs
	global_snp_list_DTR_dedup_bams_mindp100_maxdp590_minind13_minq20.regions
	global_snp_list_DTR_dedup_bams_mindp100_maxdp590_minind13_minq20.txt
	global_snp_list_DTR_dedup_bams_mindp100_maxdp590_minind13_minq20.txt.bin
	global_snp_list_DTR_dedup_bams_mindp100_maxdp590_minind13_minq20.txt.idx

## Check output
### The quick and dirty first pass
The log output will actually end up in in your slurm `.out` file, not the .log file - so that will be empty. I changed the named of the slurm.err file to `DTR_dedup_bams_mindp100_maxdp590_minind13_minq20.log` after it ran so I don't accidentally rm it when I'm cleaning up. :) \
Anyway, I checked the new .log file for some info using `grep`\

	grep "Total number of sites analyzed:" *.log 
	> Total number of sites analyzed: 866405756 # this is how many bp or positions there in the ref genome I used
	grep "Number of sites retained after filtering:" *.log
	> Number of sites retained after filtering: 22573846 # filtered snps we're working with
### For realzies	
Use the below script to see how far we should go with the trimmed SNP, then re-run the above SNP calling script
We are shooting for a normal distribution.vim If it looks weird, redo with different filters (follow suggestions in read_count exactly)

`2-get_depthinfo_plots.mpi`

	#!/bin/bash
	#
	#SBATCH --job-name r_snp_depth_plots
	#SBATCH --output %A_r_snp_depth_plots.out
	#SBATCH --error %A_r_snp_depth_plots.err
	#SBATCH --mail-type=ALL
	#SBATCH --mail-user=mabrober@ucsc.edu
	#SBATCH --time=15-00:00:00
	#SBATCH --partition 128x24
	#SBATCH --mem=120GB   #
	#SBATCH -n 24

	POS=/hb/groups/bernardi_lab/may/DTR/population-analysis/angsd/DTR_dedup_bams_mindp100_maxdp590_minind13_minq20.pos.gz
	zcat $POS | tail -n +2 | cut -f3 | sort -n | uniq -c > /hb/groups/bernardi_lab/may/DTR/population-analysis/angsd/DTR_dedup_bams_global_snp_depth_histogram_mindp39_maxdp350_minind21_minq20.txt

	module load miniconda3.9
	conda activate tidyverse

	Rscript 2-get_depthinfo_plots.r
	
`2-get_depthinfo_plots.r`

	library(tidyverse)
	library(cowplot)

	basedir <- '/hb/groups/bernardi_lab/may/DTR/population-analysis/angsd/'
	snp_depth <- read_table("/hb/groups/bernardi_lab/may/DTR/population-analysis/angsd/DTR_dedup_bams_global_snp_depth_histogram_mindp39_maxdp350_minind21_minq20.txt", col_names = F) %>%
	  transmute(count=X1, depth=X2)
	snp_count<-sum(snp_depth$count)

	png(paste0(basedir,"DTR_dedup_bams_global_snp_depth_histogram.png"),  width = 2000, height = 1500, units = "px")
	ggplot(snp_depth, aes(x=depth, y=count)) +
	  geom_freqpoly(stat = "identity") +
	  geom_vline(data=arrange(snp_depth, desc(count))[1,], aes(xintercept=depth), color="blue") +
	  annotate("text", x=90, y=2.6*10^4, label=paste0("mode depth=", arrange(snp_depth, desc(count))[1,2]), color="blue") +
	  geom_vline(aes(xintercept=sum(depth*count)/sum(count))) +
	  annotate("text", x=90, y=2.5*10^4, label=paste0("mean depth=", round(sum(snp_depth$depth*snp_depth$count)/sum(snp_depth$count), 1))) + annotate("text", x=120, y=2.7*10^4, label=paste0(round(snp_count/10^6,2), " million SNPs before filtering"), color = 'red') +
	  theme_cowplot()
	dev.off()

	cat('A total of ', round(sum(snp_depth$count)/10^6, 2),' million SNPs are generated for 132 individuals. Among these, the mean depth summed across all individuals is ',round(sum(snp_depth$depth*snp_depth$count)/sum(snp_depth$count),1),' and the mode is ', arrange(snp_depth, count)%>%tail(n=1)%>%.[[1,2]],'.')

Output of this looks like:\
"A total of  22.57  million SNPs are generated for 132 individuals. Among these, the mean depth summed across all individuals is  297.6  and the mode is  313 ."\
The plot : DTR_dedup_bams_global_snp_depth_histogram.png -WE're aiming for a normal distribution...I don't know if this qualifies, checking with Liam.
![Alt text](https://github.com/mayroberts/lcwgs-population-analysis-minus-the-cursing/blob/0666875c173c2404b4b27f9624f7f644b6f34d76/DTR_dedup_bams_global_snp_depth_histogram.png)

